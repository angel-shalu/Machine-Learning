{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0339a00-ab12-4e8d-a91c-12a47e69498b",
   "metadata": {},
   "source": [
    "**Multiple Linear Regression (MLR)** \n",
    "\n",
    "  \n",
    "This notebook contains **step-by-step code, explanation, and interpretation** for building and evaluating a **Multiple Linear Regression (MLR)** model using Python.\n",
    "\n",
    "It is designed for **teaching and learning purposes**, and also simulates a real-world business scenario where a company wants to identify **which department or factor most strongly impacts promotions** — to decide where to invest their time and resources.\n",
    "\n",
    "**Learning Objectives**\n",
    "\n",
    "- Understand how **Multiple Linear Regression (MLR)** works behind the scenes\n",
    "- Learn to **preprocess data**: encoding, cleaning, reshaping\n",
    "- Apply and interpret **linear regression model**\n",
    "- Use **OLS (Ordinary Least Squares)** to get detailed statistics\n",
    "- Perform **Backward Elimination** using p-values\n",
    "- Understand concepts like:\n",
    "  - **Bias and Variance**\n",
    "  - **Intercepts and Coefficients**\n",
    "  - **Adjusted R² vs R²**\n",
    "  - **T-Test & p-values**\n",
    "  - **Feature Elimination**\n",
    "  - Basic idea of **API (Application Programming Interface)**\n",
    "\n",
    "\n",
    "\n",
    "**Tools & Libraries Used**\n",
    "    \n",
    "- **Python** \n",
    "- **NumPy** – numerical operations\n",
    "- **Pandas** – data manipulation\n",
    "- **Matplotlib** – visualization\n",
    "- **scikit-learn** – machine learning\n",
    "- **statsmodels** – statistical modeling\n",
    "\n",
    "\n",
    "**Final Goal:**\n",
    "\n",
    "To help a company answer:\n",
    "    \n",
    "> \"**Which department or variable impacts promotion the most, so we can confidently invest in it?**\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c317c793-1b82-4439-a63a-41a2bb7858ee",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33cb5dc9-91c2-44b4-a668-beb1cf232796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b0adad-f410-4aae-b525-7ae5a9b36024",
   "metadata": {},
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eda2db-882a-4b8f-a154-a26151a1f471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DigitalMarketing</th>\n",
       "      <th>Promotion</th>\n",
       "      <th>Research</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DigitalMarketing  Promotion   Research      State     Profit\n",
       "0         165349.20  136897.80  471784.10  Hyderabad  192261.83\n",
       "1         162597.70  151377.59  443898.53  Bangalore  191792.06\n",
       "2         153441.51  101145.55  407934.54    Chennai  191050.39\n",
       "3         144372.41  118671.85  383199.62  Hyderabad  182901.99\n",
       "4         142107.34   91391.77  366168.42    Chennai  166187.94"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\shali\\Desktop\\DS_Road_Map\\8. Machine Learning\\Regression\\Multiple_Linear_Regression\\Investment.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f7bd12-56f4-4a18-88a6-f4fba01ffb05",
   "metadata": {},
   "source": [
    "# Understand the Data \n",
    "\n",
    "Let's view the available columns and understand the structure of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfa30004-0c7b-4a7d-89af-6f6a8d6ea382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   DigitalMarketing  50 non-null     float64\n",
      " 1   Promotion         50 non-null     float64\n",
      " 2   Research          50 non-null     float64\n",
      " 3   State             50 non-null     object \n",
      " 4   Profit            50 non-null     float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa78729b-6dca-421a-a1b5-b58687b8426e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DigitalMarketing', 'Promotion', 'Research', 'State', 'Profit'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns #View Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f99eb563-b32f-4549-b7a2-94f30f86eae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DigitalMarketing</th>\n",
       "      <th>Promotion</th>\n",
       "      <th>Research</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>73721.615600</td>\n",
       "      <td>121344.639600</td>\n",
       "      <td>211025.097800</td>\n",
       "      <td>112012.639200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>45902.256482</td>\n",
       "      <td>28017.802755</td>\n",
       "      <td>122290.310726</td>\n",
       "      <td>40306.180338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>51283.140000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14681.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39936.370000</td>\n",
       "      <td>103730.875000</td>\n",
       "      <td>129300.132500</td>\n",
       "      <td>90138.902500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>73051.080000</td>\n",
       "      <td>122699.795000</td>\n",
       "      <td>212716.240000</td>\n",
       "      <td>107978.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>101602.800000</td>\n",
       "      <td>144842.180000</td>\n",
       "      <td>299469.085000</td>\n",
       "      <td>139765.977500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>165349.200000</td>\n",
       "      <td>182645.560000</td>\n",
       "      <td>471784.100000</td>\n",
       "      <td>192261.830000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DigitalMarketing      Promotion       Research         Profit\n",
       "count         50.000000      50.000000      50.000000      50.000000\n",
       "mean       73721.615600  121344.639600  211025.097800  112012.639200\n",
       "std        45902.256482   28017.802755  122290.310726   40306.180338\n",
       "min            0.000000   51283.140000       0.000000   14681.400000\n",
       "25%        39936.370000  103730.875000  129300.132500   90138.902500\n",
       "50%        73051.080000  122699.795000  212716.240000  107978.190000\n",
       "75%       101602.800000  144842.180000  299469.085000  139765.977500\n",
       "max       165349.200000  182645.560000  471784.100000  192261.830000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "652e114c-59de-4a45-a536-904100d68e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DigitalMarketing    0\n",
       "Promotion           0\n",
       "Research            0\n",
       "State               0\n",
       "Profit              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3f0d0c-26b4-43fa-9b17-44f03e5e586b",
   "metadata": {},
   "source": [
    "# Define Independent & Dependent Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95df77e1-f036-4348-9f17-1b26f5fb8333",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]  # All columns except last\n",
    "y = df.iloc[:, -4]   # Target variable (you can change it based on dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4726e25d-076c-428c-9354-d9b473f0c7c5",
   "metadata": {},
   "source": [
    "# Encode Categorical Data (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "821a6745-0908-4cec-8587-14fd81758bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    DigitalMarketing  Promotion   Research  State_Bangalore  State_Chennai  \\\n",
      "0          165349.20  136897.80  471784.10                0              0   \n",
      "1          162597.70  151377.59  443898.53                1              0   \n",
      "2          153441.51  101145.55  407934.54                0              1   \n",
      "3          144372.41  118671.85  383199.62                0              0   \n",
      "4          142107.34   91391.77  366168.42                0              1   \n",
      "5          131876.90   99814.71  362861.36                0              0   \n",
      "6          134615.46  147198.87  127716.82                1              0   \n",
      "7          130298.13  145530.06  323876.68                0              1   \n",
      "8          120542.52  148718.95  311613.29                0              0   \n",
      "9          123334.88  108679.17  304981.62                1              0   \n",
      "10         101913.08  110594.11  229160.95                0              1   \n",
      "11         100671.96   91790.61  249744.55                1              0   \n",
      "12          93863.75  127320.38  249839.44                0              1   \n",
      "13          91992.39  135495.07  252664.93                1              0   \n",
      "14         119943.24  156547.42  256512.92                0              1   \n",
      "15         114523.61  122616.84  261776.23                0              0   \n",
      "16          78013.11  121597.55  264346.06                1              0   \n",
      "17          94657.16  145077.58  282574.31                0              0   \n",
      "18          91749.16  114175.79  294919.57                0              1   \n",
      "19          86419.70  153514.11       0.00                0              0   \n",
      "20          76253.86  113867.30  298664.47                1              0   \n",
      "21          78389.47  153773.43  299737.29                0              0   \n",
      "22          73994.56  122782.75  303319.26                0              1   \n",
      "23          67532.53  105751.03  304768.73                0              1   \n",
      "24          77044.01   99281.34  140574.81                0              0   \n",
      "25          64664.71  139553.16  137962.62                1              0   \n",
      "26          75328.87  144135.98  134050.07                0              1   \n",
      "27          72107.60  127864.55  353183.81                0              0   \n",
      "28          66051.52  182645.56  118148.20                0              1   \n",
      "29          65605.48  153032.06  107138.38                0              0   \n",
      "30          61994.48  115641.28   91131.24                0              1   \n",
      "31          61136.38  152701.92   88218.23                0              0   \n",
      "32          63408.86  129219.61   46085.25                1              0   \n",
      "33          55493.95  103057.49  214634.81                0              1   \n",
      "34          46426.07  157693.92  210797.67                1              0   \n",
      "35          46014.02   85047.44  205517.64                0              0   \n",
      "36          28663.76  127056.21  201126.82                0              1   \n",
      "37          44069.95   51283.14  197029.42                1              0   \n",
      "38          20229.59   65947.93  185265.10                0              0   \n",
      "39          38558.51   82982.09  174999.30                1              0   \n",
      "40          28754.33  118546.05  172795.67                1              0   \n",
      "41          27892.92   84710.77  164470.71                0              1   \n",
      "42          23640.93   96189.63  148001.11                1              0   \n",
      "43          15505.73  127382.30   35534.17                0              0   \n",
      "44          22177.74  154806.14   28334.72                1              0   \n",
      "45           1000.23  124153.04    1903.93                0              0   \n",
      "46           1315.46  115816.21  297114.46                0              1   \n",
      "47              0.00  135426.92       0.00                1              0   \n",
      "48            542.05   51743.15       0.00                0              0   \n",
      "49              0.00  116983.80   45173.06                1              0   \n",
      "\n",
      "    State_Hyderabad  \n",
      "0                 1  \n",
      "1                 0  \n",
      "2                 0  \n",
      "3                 1  \n",
      "4                 0  \n",
      "5                 1  \n",
      "6                 0  \n",
      "7                 0  \n",
      "8                 1  \n",
      "9                 0  \n",
      "10                0  \n",
      "11                0  \n",
      "12                0  \n",
      "13                0  \n",
      "14                0  \n",
      "15                1  \n",
      "16                0  \n",
      "17                1  \n",
      "18                0  \n",
      "19                1  \n",
      "20                0  \n",
      "21                1  \n",
      "22                0  \n",
      "23                0  \n",
      "24                1  \n",
      "25                0  \n",
      "26                0  \n",
      "27                1  \n",
      "28                0  \n",
      "29                1  \n",
      "30                0  \n",
      "31                1  \n",
      "32                0  \n",
      "33                0  \n",
      "34                0  \n",
      "35                1  \n",
      "36                0  \n",
      "37                0  \n",
      "38                1  \n",
      "39                0  \n",
      "40                0  \n",
      "41                0  \n",
      "42                0  \n",
      "43                1  \n",
      "44                0  \n",
      "45                1  \n",
      "46                0  \n",
      "47                0  \n",
      "48                1  \n",
      "49                0  \n"
     ]
    }
   ],
   "source": [
    "X = pd.get_dummies(X, dtype=int)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554f1f6f-fe62-427d-b685-cd9eceb8d07d",
   "metadata": {},
   "source": [
    "# Split the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "691c261d-42e1-4747-b2eb-910ae9192f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f99ea0-d001-46a5-ae4d-019e051fa361",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8c732a1-3241-4d93-aebe-8ca4953984b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy_X',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">copy_X&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">1e-06</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('positive',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">positive&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d57898b-9e09-4bed-ba35-5eb4d919ba47",
   "metadata": {},
   "source": [
    "# Predict and Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9839ef1-1dfb-4774-858a-3cc67aecbb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[182645.56  91790.61 110594.11  84710.77 101145.55 127864.55  65947.93\n",
      " 152701.92 122782.75  91391.77]\n"
     ]
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fee2f2b-32f1-4902-817e-b4fa67284825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Actual  Predicted\n",
      "28  182645.56  182645.56\n",
      "11   91790.61   91790.61\n",
      "10  110594.11  110594.11\n",
      "41   84710.77   84710.77\n",
      "2   101145.55  101145.55\n"
     ]
    }
   ],
   "source": [
    "comparison = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "print(comparison.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3161341-77a8-4026-811e-297c9730ad46",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1d9b63c-5e23-4b39-bad0-c3369c6058da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias (Train Accuracy): 1.0\n",
      "Variance (Test Accuracy): 1.0\n"
     ]
    }
   ],
   "source": [
    "bias = regressor.score(X_train, y_train)\n",
    "variance = regressor.score(X_test, y_test)\n",
    "\n",
    "print(\"Bias (Train Accuracy):\", bias)\n",
    "print(\"Variance (Test Accuracy):\", variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623ac0b6-0397-4ebd-8e9e-4e8666e2786d",
   "metadata": {},
   "source": [
    "# Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90fadad4-d3ab-4b8a-ba8c-fd5ef3914883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope/Co-efficients (b₁): [-3.58815785e-16  1.00000000e+00 -3.89677049e-17 -1.53880995e-13\n",
      "  3.15122730e-13 -1.61241735e-13]\n"
     ]
    }
   ],
   "source": [
    "m_slope = regressor.coef_\n",
    "print(\"Slope/Co-efficients (b₁):\", m_slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b98e97f-bad6-4775-bb38-b2dfdebe715d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept (b₀): 8.731149137020111e-11\n"
     ]
    }
   ],
   "source": [
    "c_intercept = regressor.intercept_\n",
    "print(\"Intercept (b₀):\", c_intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4813775c-439f-4872-bc7f-b65c2db9aa3b",
   "metadata": {},
   "source": [
    "# Add Constant for OLS\n",
    "\n",
    "OLS (Ordinary Least Squares) from `statsmodels` requires a constant column to represent the intercept.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1edded-88fa-4e1f-b8b6-42af53f5b0d6",
   "metadata": {},
   "source": [
    "# Add Constant Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2af2bbb9-aace-4705-90ba-e9bca15a254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.append(arr=np.ones((X.shape[0], 1)).astype(int), values=X, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47954e1-1c94-4706-ad50-34ba0a4963c0",
   "metadata": {},
   "source": [
    "# Backward Elimination (Full Features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ea0b564-0b5c-4e18-b7c8-cabf521a7402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>Promotion</td>    <th>  R-squared:         </th> <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>7.500e+29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 11 Jul 2025</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:07:08</td>     <th>  Log-Likelihood:    </th> <td>  1082.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>  -2154.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    44</td>      <th>  BIC:               </th> <td>  -2142.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>-3.638e-11</td> <td> 7.46e-11</td> <td>   -0.488</td> <td> 0.628</td> <td>-1.87e-10</td> <td> 1.14e-10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>-1.943e-16</td> <td> 4.98e-16</td> <td>   -0.390</td> <td> 0.698</td> <td> -1.2e-15</td> <td> 8.09e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    1.0000</td> <td>  5.6e-16</td> <td> 1.78e+15</td> <td> 0.000</td> <td>    1.000</td> <td>    1.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> 3.469e-16</td> <td> 1.84e-16</td> <td>    1.886</td> <td> 0.066</td> <td>-2.37e-17</td> <td> 7.18e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td> 2.183e-11</td> <td> 3.49e-11</td> <td>    0.625</td> <td> 0.535</td> <td>-4.86e-11</td> <td> 9.22e-11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td> 7.276e-12</td> <td> 3.58e-11</td> <td>    0.203</td> <td> 0.840</td> <td>-6.49e-11</td> <td> 7.95e-11</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.163</td> <th>  Durbin-Watson:     </th> <td>   0.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.922</td> <th>  Jarque-Bera (JB):  </th> <td>   0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.066</td> <th>  Prob(JB):          </th> <td>   0.980</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.953</td> <th>  Cond. No.          </th> <td>1.47e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.47e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &    Promotion     & \\textbf{  R-squared:         } &     1.000   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     1.000   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } & 7.500e+29   \\\\\n",
       "\\textbf{Date:}             & Fri, 11 Jul 2025 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}             &     11:07:08     & \\textbf{  Log-Likelihood:    } &    1082.9   \\\\\n",
       "\\textbf{No. Observations:} &          50      & \\textbf{  AIC:               } &    -2154.   \\\\\n",
       "\\textbf{Df Residuals:}     &          44      & \\textbf{  BIC:               } &    -2142.   \\\\\n",
       "\\textbf{Df Model:}         &           5      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &   -3.638e-11  &     7.46e-11     &    -0.488  &         0.628        &    -1.87e-10    &     1.14e-10     \\\\\n",
       "\\textbf{x1}    &   -1.943e-16  &     4.98e-16     &    -0.390  &         0.698        &     -1.2e-15    &     8.09e-16     \\\\\n",
       "\\textbf{x2}    &       1.0000  &      5.6e-16     &  1.78e+15  &         0.000        &        1.000    &        1.000     \\\\\n",
       "\\textbf{x3}    &    3.469e-16  &     1.84e-16     &     1.886  &         0.066        &    -2.37e-17    &     7.18e-16     \\\\\n",
       "\\textbf{x4}    &    2.183e-11  &     3.49e-11     &     0.625  &         0.535        &    -4.86e-11    &     9.22e-11     \\\\\n",
       "\\textbf{x5}    &    7.276e-12  &     3.58e-11     &     0.203  &         0.840        &    -6.49e-11    &     7.95e-11     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.163 & \\textbf{  Durbin-Watson:     } &    0.214  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.922 & \\textbf{  Jarque-Bera (JB):  } &    0.041  \\\\\n",
       "\\textbf{Skew:}          &  0.066 & \\textbf{  Prob(JB):          } &    0.980  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.953 & \\textbf{  Cond. No.          } & 1.47e+06  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.47e+06. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              Promotion   R-squared:                       1.000\n",
       "Model:                            OLS   Adj. R-squared:                  1.000\n",
       "Method:                 Least Squares   F-statistic:                 7.500e+29\n",
       "Date:                Fri, 11 Jul 2025   Prob (F-statistic):               0.00\n",
       "Time:                        11:07:08   Log-Likelihood:                 1082.9\n",
       "No. Observations:                  50   AIC:                            -2154.\n",
       "Df Residuals:                      44   BIC:                            -2142.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const      -3.638e-11   7.46e-11     -0.488      0.628   -1.87e-10    1.14e-10\n",
       "x1         -1.943e-16   4.98e-16     -0.390      0.698    -1.2e-15    8.09e-16\n",
       "x2             1.0000    5.6e-16   1.78e+15      0.000       1.000       1.000\n",
       "x3          3.469e-16   1.84e-16      1.886      0.066   -2.37e-17    7.18e-16\n",
       "x4          2.183e-11   3.49e-11      0.625      0.535   -4.86e-11    9.22e-11\n",
       "x5          7.276e-12   3.58e-11      0.203      0.840   -6.49e-11    7.95e-11\n",
       "==============================================================================\n",
       "Omnibus:                        0.163   Durbin-Watson:                   0.214\n",
       "Prob(Omnibus):                  0.922   Jarque-Bera (JB):                0.041\n",
       "Skew:                           0.066   Prob(JB):                        0.980\n",
       "Kurtosis:                       2.953   Cond. No.                     1.47e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.47e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X_opt = X[:, [0, 1, 2, 3, 4, 5]]  # Example: adjust as per your column count\n",
    "regressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be82871-e4af-4e6c-9494-cabb1babb712",
   "metadata": {},
   "source": [
    "**OLS Regression Results – Full Explanation**\n",
    "\n",
    "**Context:**\n",
    "\n",
    "You ran the following code:\n",
    "\n",
    "```python\n",
    "X_opt = X[:, [0, 1, 2, 3, 4, 5]]\n",
    "regressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()\n",
    "regressor_OLS.summary()\n",
    "```\n",
    "\n",
    "**Part-by-Part Explanation of the Output**\n",
    "\n",
    "\n",
    "**Header Summary**\n",
    "\n",
    "| Term                 | Meaning                                                             |\n",
    "| -------------------- | ------------------------------------------------------------------- |\n",
    "| **Dep. Variable**    | `Promotion`: The dependent variable (target/output)                 |\n",
    "| **Model**            | `OLS` = Ordinary Least Squares Regression                           |\n",
    "| **Method**           | Least Squares method used to estimate coefficients                  |\n",
    "| **No. Observations** | 50 data points (rows in dataset)                                    |\n",
    "| **Df Residuals**     | 44 = 50 - 6 → total observations minus number of model coefficients |\n",
    "| **Df Model**         | 5 → You used 5 predictors (x1 to x5)                                |\n",
    "| **Covariance Type**  | Non-robust standard errors used                                     |\n",
    "\n",
    "\n",
    "**Model Quality Metrics**\n",
    "\n",
    "| Metric                 | Value                      | Meaning                                                                                                     |\n",
    "| ---------------------- | -------------------------- | ----------------------------------------------------------------------------------------------------------- |\n",
    "| **R-squared**          | `1.000`                    | Model explains **100%** of variance in target. This usually indicates **overfitting** or multicollinearity. |\n",
    "| **Adj. R-squared**     | `1.000`                    | Adjusted for number of predictors. Still 1.000 → very high!                                                 |\n",
    "| **F-statistic**        | `7.5e+29`                  | Very high → model is statistically significant                                                              |\n",
    "| **Prob (F-statistic)** | `0.00`                     | p-value for F-test is 0 → the model overall is significant                                                  |\n",
    "| **AIC / BIC**          | AIC: `-2154`, BIC: `-2142` | Lower values indicate a better model (used for comparing models)                                            |\n",
    "\n",
    "\n",
    "**Coefficient Table (Main Focus)**\n",
    "\n",
    "| Term   | Coef        | Std Err     | t       | P > | Significance         |\n",
    "|--------|-------------|-------------|---------|------|----------------------|\n",
    "| const  | -3.638e-11  | 7.46e-11    | -0.488  | 0.628| ❌ Not significant    |\n",
    "| x1     | -1.943e-16  | 4.98e-16    | -0.390  | 0.698| ❌ Not significant    |\n",
    "| x2     | 1.0000      | 5.6e-16     | 1.78e+15| 0.000| ✅ Highly significant |\n",
    "| x3     | 3.469e-16   | 1.84e-16    | 1.886   | 0.066| ⚠️ Borderline         |\n",
    "| x4     | 2.183e-11   | 3.49e-11    | 0.625   | 0.535| ❌ Not significant    |\n",
    "| x5     | 7.276e-12   | 3.58e-11    | 0.203   | 0.840| ❌ Not significant    |\n",
    "\n",
    "\n",
    "**How to Interpret This?**\n",
    "\n",
    "- **Coef (Coefficient)**: The amount of change in the target variable for 1 unit change in that predictor.\n",
    "- **P > |t| (p-value)**: Tells you whether the variable is statistically significant.\n",
    "  - If **p < 0.05**, the variable is **significant** → Keep it.\n",
    "  - If **p ≥ 0.05**, the variable is **not significant** → You can remove it (Backward Elimination).\n",
    "- **t** and **Std Err**: Used internally to compute the p-value.\n",
    "- Based on this table:\n",
    "  - Keep only `x2`\n",
    "  - Remove variables like `x1`, `x4`, `x5`\n",
    "\n",
    "\n",
    "**Statistical Tests**\n",
    "\n",
    "| Metric              | Value                                                               | Meaning |\n",
    "| ------------------- | ------------------------------------------------------------------- | ------- |\n",
    "| **Omnibus / JB**    | These test if residuals are normally distributed (good if p > 0.05) |         |\n",
    "| **Durbin-Watson**   | `0.214` → indicates **strong positive autocorrelation** (bad!)      |         |\n",
    "| **Skew / Kurtosis** | `Skew ≈ 0`, `Kurtosis ≈ 3` → residuals are normally distributed     |         |\n",
    "| **Cond. No.**       | `1.47e+06` → very high → indicates **multicollinearity risk** (bad) |         |\n",
    "\n",
    "\n",
    "\n",
    "**What to Do Next? → Backward Elimination**\n",
    "\n",
    "Based on this summary:\n",
    "\n",
    "* Remove the variable with **highest p-value > 0.05** → `x5` (`0.840`)\n",
    "* Rerun OLS without it\n",
    "* Repeat the process until all p-values < 0.05\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df15ebc4-6354-445e-b18f-f795e21120fb",
   "metadata": {},
   "source": [
    "**OLS Regression Results**\n",
    "\n",
    "We started with 5 independent variables (x1 to x5) and added a constant term.\n",
    "\n",
    "**Summary Highlights:**\n",
    "\n",
    "- **R-squared = 1.000** → Model fits data perfectly (possible overfitting)\n",
    "- **Only x2 is statistically significant (p < 0.05)**\n",
    "- **x1, x4, x5 have high p-values → should be removed**\n",
    "- **Durbin-Watson = 0.214** → Indicates autocorrelation (not ideal)\n",
    "- **Condition Number = 1.47e+06** → Multicollinearity suspected\n",
    "\n",
    "**Next Step:**\n",
    "Perform **Backward Elimination**:\n",
    "- Remove variable with highest p-value (`x5`)\n",
    "- Rerun the model\n",
    "- Continue until all p-values < 0.05\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d985b03b-d33c-4eca-b5db-34e488c9a84b",
   "metadata": {},
   "source": [
    "# Remove Feature with Highest p-value\n",
    "Keep repeating this by removing the feature with the highest p-value above 0.05 until all remaining features are significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ff128bf-5500-432a-be6b-3b173946cf77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>Promotion</td>    <th>  R-squared:         </th> <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>1.217e+30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 11 Jul 2025</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:22:39</td>     <th>  Log-Likelihood:    </th> <td>  1088.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>  -2168.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    45</td>      <th>  BIC:               </th> <td>  -2158.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>-1.164e-10</td> <td> 6.47e-11</td> <td>   -1.798</td> <td> 0.079</td> <td>-2.47e-10</td> <td>  1.4e-11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>-1.943e-16</td> <td> 4.35e-16</td> <td>   -0.447</td> <td> 0.657</td> <td>-1.07e-15</td> <td> 6.82e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    1.0000</td> <td> 4.91e-16</td> <td> 2.04e+15</td> <td> 0.000</td> <td>    1.000</td> <td>    1.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>-3.886e-16</td> <td> 1.59e-16</td> <td>   -2.442</td> <td> 0.019</td> <td>-7.09e-16</td> <td>-6.81e-17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>-7.276e-12</td> <td> 2.69e-11</td> <td>   -0.270</td> <td> 0.788</td> <td>-6.15e-11</td> <td>  4.7e-11</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.887</td> <th>  Durbin-Watson:     </th> <td>   0.742</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.389</td> <th>  Jarque-Bera (JB):  </th> <td>   1.425</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.208</td> <th>  Prob(JB):          </th> <td>   0.491</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.285</td> <th>  Cond. No.          </th> <td>1.44e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.44e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &    Promotion     & \\textbf{  R-squared:         } &     1.000   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     1.000   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } & 1.217e+30   \\\\\n",
       "\\textbf{Date:}             & Fri, 11 Jul 2025 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}             &     11:22:39     & \\textbf{  Log-Likelihood:    } &    1088.9   \\\\\n",
       "\\textbf{No. Observations:} &          50      & \\textbf{  AIC:               } &    -2168.   \\\\\n",
       "\\textbf{Df Residuals:}     &          45      & \\textbf{  BIC:               } &    -2158.   \\\\\n",
       "\\textbf{Df Model:}         &           4      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &   -1.164e-10  &     6.47e-11     &    -1.798  &         0.079        &    -2.47e-10    &      1.4e-11     \\\\\n",
       "\\textbf{x1}    &   -1.943e-16  &     4.35e-16     &    -0.447  &         0.657        &    -1.07e-15    &     6.82e-16     \\\\\n",
       "\\textbf{x2}    &       1.0000  &     4.91e-16     &  2.04e+15  &         0.000        &        1.000    &        1.000     \\\\\n",
       "\\textbf{x3}    &   -3.886e-16  &     1.59e-16     &    -2.442  &         0.019        &    -7.09e-16    &    -6.81e-17     \\\\\n",
       "\\textbf{x4}    &   -7.276e-12  &     2.69e-11     &    -0.270  &         0.788        &    -6.15e-11    &      4.7e-11     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  1.887 & \\textbf{  Durbin-Watson:     } &    0.742  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.389 & \\textbf{  Jarque-Bera (JB):  } &    1.425  \\\\\n",
       "\\textbf{Skew:}          & -0.208 & \\textbf{  Prob(JB):          } &    0.491  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.285 & \\textbf{  Cond. No.          } & 1.44e+06  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.44e+06. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              Promotion   R-squared:                       1.000\n",
       "Model:                            OLS   Adj. R-squared:                  1.000\n",
       "Method:                 Least Squares   F-statistic:                 1.217e+30\n",
       "Date:                Fri, 11 Jul 2025   Prob (F-statistic):               0.00\n",
       "Time:                        11:22:39   Log-Likelihood:                 1088.9\n",
       "No. Observations:                  50   AIC:                            -2168.\n",
       "Df Residuals:                      45   BIC:                            -2158.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const      -1.164e-10   6.47e-11     -1.798      0.079   -2.47e-10     1.4e-11\n",
       "x1         -1.943e-16   4.35e-16     -0.447      0.657   -1.07e-15    6.82e-16\n",
       "x2             1.0000   4.91e-16   2.04e+15      0.000       1.000       1.000\n",
       "x3         -3.886e-16   1.59e-16     -2.442      0.019   -7.09e-16   -6.81e-17\n",
       "x4         -7.276e-12   2.69e-11     -0.270      0.788   -6.15e-11     4.7e-11\n",
       "==============================================================================\n",
       "Omnibus:                        1.887   Durbin-Watson:                   0.742\n",
       "Prob(Omnibus):                  0.389   Jarque-Bera (JB):                1.425\n",
       "Skew:                          -0.208   Prob(JB):                        0.491\n",
       "Kurtosis:                       2.285   Cond. No.                     1.44e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.44e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:, [0, 1, 2, 3, 4]]  # Removed 5th feature\n",
    "regressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6a42f5-b8f7-480f-a8ed-abbc6632cda6",
   "metadata": {},
   "source": [
    "# Final Model after Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5aff3201-3520-41f5-a16e-9766bdc15c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>Promotion</td>    <th>  R-squared:         </th> <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>4.132e+31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 11 Jul 2025</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:23:02</td>     <th>  Log-Likelihood:    </th> <td>  1140.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>  -2277.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    48</td>      <th>  BIC:               </th> <td>  -2274.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>-5.457e-11</td> <td> 1.94e-11</td> <td>   -2.818</td> <td> 0.007</td> <td>-9.35e-11</td> <td>-1.56e-11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    1.0000</td> <td> 1.56e-16</td> <td> 6.43e+15</td> <td> 0.000</td> <td>    1.000</td> <td>    1.000</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>50.890</td> <th>  Durbin-Watson:     </th> <td>   0.057</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 632.888</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-2.078</td> <th>  Prob(JB):          </th> <td>3.72e-138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>19.927</td> <th>  Cond. No.          </th> <td>5.59e+05</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.59e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &    Promotion     & \\textbf{  R-squared:         } &     1.000   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     1.000   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } & 4.132e+31   \\\\\n",
       "\\textbf{Date:}             & Fri, 11 Jul 2025 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}             &     11:23:02     & \\textbf{  Log-Likelihood:    } &    1140.7   \\\\\n",
       "\\textbf{No. Observations:} &          50      & \\textbf{  AIC:               } &    -2277.   \\\\\n",
       "\\textbf{Df Residuals:}     &          48      & \\textbf{  BIC:               } &    -2274.   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &   -5.457e-11  &     1.94e-11     &    -2.818  &         0.007        &    -9.35e-11    &    -1.56e-11     \\\\\n",
       "\\textbf{x1}    &       1.0000  &     1.56e-16     &  6.43e+15  &         0.000        &        1.000    &        1.000     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 50.890 & \\textbf{  Durbin-Watson:     } &     0.057  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &   632.888  \\\\\n",
       "\\textbf{Skew:}          & -2.078 & \\textbf{  Prob(JB):          } & 3.72e-138  \\\\\n",
       "\\textbf{Kurtosis:}      & 19.927 & \\textbf{  Cond. No.          } &  5.59e+05  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 5.59e+05. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              Promotion   R-squared:                       1.000\n",
       "Model:                            OLS   Adj. R-squared:                  1.000\n",
       "Method:                 Least Squares   F-statistic:                 4.132e+31\n",
       "Date:                Fri, 11 Jul 2025   Prob (F-statistic):               0.00\n",
       "Time:                        11:23:02   Log-Likelihood:                 1140.7\n",
       "No. Observations:                  50   AIC:                            -2277.\n",
       "Df Residuals:                      48   BIC:                            -2274.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const      -5.457e-11   1.94e-11     -2.818      0.007   -9.35e-11   -1.56e-11\n",
       "x1             1.0000   1.56e-16   6.43e+15      0.000       1.000       1.000\n",
       "==============================================================================\n",
       "Omnibus:                       50.890   Durbin-Watson:                   0.057\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              632.888\n",
       "Skew:                          -2.078   Prob(JB):                    3.72e-138\n",
       "Kurtosis:                      19.927   Cond. No.                     5.59e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.59e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:, [0, 2]]  # Final selected features\n",
    "regressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5679d4e4-1cfc-487d-9fdf-85251f8f91ad",
   "metadata": {},
   "source": [
    "# Concept Highlights\n",
    "\n",
    "- **API** (Application Programming Interface): Connects front-end to back-end.\n",
    "- **OLS**: A statistical method to fit linear regression.\n",
    "- **p-value**: Helps determine if a feature is statistically significant (p < 0.05 is good).\n",
    "- **T-test**: Performed on sample data to test hypothesis.\n",
    "- **Backward Elimination**: A feature selection method based on p-values.\n",
    "- **Adjusted R² > R²**: Indicates a better, more reliable model when adding/removing variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d576660-415a-487a-9fbe-d74338b11e02",
   "metadata": {},
   "source": [
    "# Final Decision: Which Department to Focus On?\n",
    "\n",
    "Based on statistical analysis using **Backward Elimination in OLS**, the model retained only **one important feature (x1)**, which:\n",
    "\n",
    "- Has a **p-value = 0.000** → highly significant\n",
    "- Has **coefficient = 1.0** → 1 unit increase in x1 increases promotion by 1 unit\n",
    "- Explains **100% of the variation** in the Promotion outcome (R² = 1.000)\n",
    "\n",
    "This means the department or factor represented by `x1` is **most directly responsible** for driving promotions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9899aefd-9d3c-4d35-9c6f-3a1e5a49c205",
   "metadata": {},
   "source": [
    "# **Recommendation to Company:**\n",
    "\n",
    "Focus your time, budget, and resources on the department represented by **x1** is **Department_Marketing** — this is the best area to invest in for maximizing promotions and growth.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
